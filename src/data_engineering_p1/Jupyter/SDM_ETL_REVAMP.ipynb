{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDM ETL code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importeer pandas voor DataFrames en pyodbc voor database-connecties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "aenc_conn = sqlite3.connect(\"../../../Data/Raw/Sqlite/aenc.sqlite\")\n",
    "adventureworks_conn = sqlite3.connect(\"../../../Data/Raw/Sqlite/AdventureWorks.sqlite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database Connectie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_SDM = {\"servername\": r\"143.177.235.181\", \"database\": \"SDM_DEDS_P1\", \"username\": \"sa\", \"password\": \"Str0ngP@ssword\"}\n",
    "DB_NorthWind = {\"servername\": r\"143.177.235.181\", \"database\": \"NorthWind\", \"username\": \"sa\", \"password\": \"Str0ngP@ssword\"}\n",
    "export_conn = pyodbc.connect(\n",
    "    f\"DRIVER={{ODBC Driver 18 for SQL Server}};\"\n",
    "    f\"SERVER={DB_SDM['servername']};\"\n",
    "    f\"DATABASE={DB_SDM['database']};\"\n",
    "    f\"UID={DB_SDM['username']};\"\n",
    "    f\"PWD={DB_SDM['password']};\"\n",
    "    f\"Encrypt=yes;TrustServerCertificate=yes;\"\n",
    ")\n",
    "\n",
    "NorthWind_conn = pyodbc.connect(\n",
    "    f\"DRIVER={{ODBC Driver 18 for SQL Server}};\"\n",
    "    f\"SERVER={DB_NorthWind['servername']};\"\n",
    "    f\"DATABASE={DB_NorthWind['database']};\"\n",
    "    f\"UID={DB_NorthWind['username']};\"\n",
    "    f\"PWD={DB_NorthWind['password']};\"\n",
    "    f\"Encrypt=yes;TrustServerCertificate=yes;\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames maken voor tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading sysdiagrams: Could not decode to UTF-8 column 'definition' with text '��\u0011���\u001a�'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saadz\\AppData\\Local\\Temp\\ipykernel_4832\\1853655394.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  table_names = pd.read_sql(query, connection)\n",
      "C:\\Users\\saadz\\AppData\\Local\\Temp\\ipykernel_4832\\1853655394.py:17: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dictionary[table] = pd.read_sql(f\"SELECT * FROM {table}\", connection)\n",
      "C:\\Users\\saadz\\AppData\\Local\\Temp\\ipykernel_4832\\1853655394.py:17: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dictionary[table] = pd.read_sql(f\"SELECT * FROM {table}\", connection)\n",
      "C:\\Users\\saadz\\AppData\\Local\\Temp\\ipykernel_4832\\1853655394.py:17: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dictionary[table] = pd.read_sql(f\"SELECT * FROM {table}\", connection)\n"
     ]
    }
   ],
   "source": [
    "def create_dataframes_sql(connection, db_type):\n",
    "    dictionary : dict = {}\n",
    "    query : str = \"\"\n",
    "    key : str = \"\"\n",
    "\n",
    "    if db_type == \"sqlite\":\n",
    "        query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "        key = \"name\"\n",
    "    elif db_type == \"ssms\":\n",
    "        query = \"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE = 'BASE TABLE';\"\n",
    "        key = \"TABLE_NAME\"\n",
    "\n",
    "    table_names = pd.read_sql(query, connection)\n",
    "\n",
    "    for table in table_names[key].tolist():\n",
    "        try:\n",
    "            dictionary[table] = pd.read_sql(f\"SELECT * FROM {table}\", connection)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {table}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "aenc = create_dataframes_sql(aenc_conn, \"sqlite\")\n",
    "adventureworks = create_dataframes_sql(adventureworks_conn, \"sqlite\")\n",
    "northwind = create_dataframes_sql(NorthWind_conn, \"ssms\")\n",
    "\n",
    "#Errors en warnings zijn niet erg hier als het totaal 1 error en 4 UserWarnings zijn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries met DataFrames mergen naar één Dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdm = aenc | adventureworks | northwind #Alle drie mergen in één Dictionary met alle DataFrames\n",
    "\n",
    "sdm['Products'] = sdm['Products'].rename(columns={\n",
    "    \"ProductID\": \"NWProductID\",\n",
    "    \"ProductName\": \"Name\", \n",
    "    \"UnitPrice\": \"ListPrice\"\n",
    "})\n",
    "sdm['Product'] = sdm['Product'].rename(columns={\n",
    "    \"id\": \"ProductID\",\n",
    "    \"name\": \"Name\",\n",
    "    \"prod_size\": \"Size\",\n",
    "    \"color\": \"Color\",\n",
    "    \"quantity\": \"SafetyStockLevel\",\n",
    "    \"unit_price\": \"ListPrice\"\n",
    "})\n",
    "sdm['Production_Product'] = pd.concat([sdm['Production_Product'], sdm['Products']], ignore_index=True)\n",
    "sdm['Production_Product'] = pd.concat([sdm['Production_Product'], sdm['Product']], ignore_index=True)\n",
    "sdm['Production_Product']['Weight'] = sdm['Production_Product']['Weight'].replace('', np.nan)\n",
    "sdm['Production_Product']['Weight'] = sdm['Production_Product']['Weight'].astype(float)\n",
    "del sdm['Products']\n",
    "del sdm['Product']\n",
    "\n",
    "sdm['Order_Details'] = sdm['Order_Details'].rename(columns={\n",
    "    \"OrderID\": \"SalesOrderID\",\n",
    "    \"Discount\": \"UnitPriceDiscount\",\n",
    "    \"Quantity\": \"quantity\"\n",
    "})\n",
    "sdm['Sales_Order_Item'] = sdm['Sales_Order_Item'].rename(columns={\n",
    "    \"id\": \"SalesOrderID\",\n",
    "    \"prod_id\": \"ProductID\",\n",
    "})\n",
    "sdm['Sales_SalesOrderDetail'] = pd.concat([sdm['Sales_SalesOrderDetail'], sdm['Sales_Order_Item']], ignore_index=True)\n",
    "sdm['Sales_SalesOrderDetail'] = pd.concat([sdm['Sales_SalesOrderDetail'], sdm['Order_Details']], ignore_index=True)\n",
    "del sdm['Order_Details']\n",
    "del sdm['Sales_Order_Item']\n",
    "\n",
    "\n",
    "sdm['Customer'] = sdm['Customer'].rename(columns={\"state\": \"state_id\"})\n",
    "sdm['Customers'] = sdm['Customers'].rename(columns={\n",
    "    \"CustomerID\": \"id\",\n",
    "    \"CompanyName\": \"company_name\",\n",
    "    \"Address\": \"address\",\n",
    "    \"City\": \"city\",\n",
    "    \"PostalCode\": \"zip\",\n",
    "    \"Phone\": \"phone\"\n",
    "})\n",
    "sdm['Customer'] = pd.concat([sdm['Customer'], sdm['Customers']], ignore_index=True)\n",
    "del sdm['Customers']\n",
    "\n",
    "sdm['Sales_Order'] = sdm['Sales_Order'].rename(columns={\n",
    "    \"id\": \"SalesOrderID\",\n",
    "    \"cust_id\": \"CustomerID\",\n",
    "    \"order_date\": \"OrderDate\",\n",
    "    \"sales_rep\": \"SalesPersonID\",\n",
    "    \"Region\": \"ShipRegion\"\n",
    "})\n",
    "sdm['Orders'] = sdm['Orders'].rename(columns={\n",
    "    \"OrderID\": \"SalesOrderID\",\n",
    "    \"order_date\": \"OrderDate\",\n",
    "    \"EmployeeID\": \"SalesPersonID\",\n",
    "    \"RequiredDate\": \"DueDate\",\n",
    "    \"ShippedDate\": \"ShipDate\"\n",
    "})\n",
    "\n",
    "sdm['Sales_SalesOrderHeader'] = sdm['Sales_SalesOrderHeader'].rename(columns={\"CustomerID\": \"SalesCustomerID\"})\n",
    "sdm['Sales_SalesOrderHeader'] = pd.concat([sdm['Sales_SalesOrderHeader'], sdm['Sales_Order']], ignore_index=True)\n",
    "sdm['Sales_SalesOrderHeader'] = pd.concat([sdm['Sales_SalesOrderHeader'], sdm['Orders']], ignore_index=True)\n",
    "del sdm['Sales_Order']\n",
    "del sdm['Orders']\n",
    "\n",
    "sdm['Employees'] = sdm['Employees'].rename(columns={\n",
    "    \"EmployeeID\": \"emp_id\",\n",
    "    \"LastName\": \"emp_lname\",\n",
    "    \"FirstName\": \"emp_fname\",\n",
    "    \"Address\": \"street\",\n",
    "    \"City\": \"city\",\n",
    "    \"Region\": \"state\",\n",
    "    \"PostalCode\": \"zip_code\",\n",
    "    \"HomePhone\": \"phone\",\n",
    "    \"BirthDate\": \"birth_date\",\n",
    "    \"HireDate\": \"start_date\"\n",
    "})\n",
    "sdm['Employee'] = pd.concat([sdm['Employee'], sdm['Employees']], ignore_index=True)\n",
    "del sdm['Employees']\n",
    "\n",
    "sdm['Department'] = sdm['Department'].rename(columns={\n",
    "    \"dept_id\": \"DepartmentID\",\n",
    "    \"dept_name\": \"Name\",\n",
    "})\n",
    "sdm['HumanResources_Department'] = pd.concat([sdm['HumanResources_Department'], sdm['Department']], ignore_index=True)\n",
    "sdm['Department'] = sdm['HumanResources_Department']\n",
    "del sdm['HumanResources_Department']\n",
    "\n",
    "sdm['Purchasing_PurchaseOrderDetail']['ReceivedQty'] = sdm['Purchasing_PurchaseOrderDetail']['ReceivedQty'].astype(float)\n",
    "sdm['Purchasing_PurchaseOrderDetail']['RejectedQty'] = sdm['Purchasing_PurchaseOrderDetail']['RejectedQty'].astype(float)\n",
    "sdm['Purchasing_PurchaseOrderDetail']['StockedQty'] = sdm['Purchasing_PurchaseOrderDetail']['StockedQty'].astype(float)\n",
    "\n",
    "dict_order = [\n",
    "    \"State\",\n",
    "    \"Region\",\n",
    "    \"Department\",\n",
    "    \"Employee\",\n",
    "    \"Bonus\",\n",
    "    \"Territories\",\n",
    "    \"EmployeeTerritories\",\n",
    "    \"Customer\",\n",
    "    \"CustomerDemographics\",\n",
    "    \"CustomerCustomerDemo\",\n",
    "    \"Shippers\",\n",
    "    \"Sales_SalesTerritory\",\n",
    "    \"Person_Person\",\n",
    "    \"Person_Address\",\n",
    "    \"HumanResources_Employee\",\n",
    "    \"Sales_Store\",\n",
    "    \"Sales_Customer\",\n",
    "    \"Production_ProductCategory\",\n",
    "    \"Suppliers\",\n",
    "    \"Production_Product\",\n",
    "    \"Production_BillOfMaterials\",\n",
    "    \"Purchasing_Vendor\",\n",
    "    \"Purchasing_PurchaseOrderHeader\",\n",
    "    \"Purchasing_PurchaseOrderDetail\",\n",
    "    \"Sales_SalesOrderHeader\",\n",
    "    \"Sales_SalesOrderDetail\"\n",
    "\n",
    "]               #Hierin komt dictionary order te staan.\n",
    "                #Dit moet omdat de volgorde van welke tables worden gestuurd naar database belangrijk is.\n",
    "\n",
    "sdm = {k: sdm[k] for k in dict_order if k in sdm} #Verandert de volgorde van sdm-Dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDM in SSMS vullen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading table State: 100% ✓\n",
      "Loading table Region: 100% ✓\n",
      "Loading table Department: 100% ✓\n",
      "Loading table Employee: 100% ✓\n",
      "Loading table Bonus: 100% ✓\n",
      "Loading table Territories: 100% ✓\n",
      "Loading table EmployeeTerritories: 100% ✓\n",
      "Loading table Customer: 100% ✓\n",
      "Loading table CustomerDemographics: 100% ✓\n",
      "Loading table CustomerCustomerDemo: 100% ✓\n",
      "Loading table Shippers: 100% ✓\n",
      "Loading table Sales_SalesTerritory: 100% ✓\n",
      "Loading table Person_Person: 100% ✓\n",
      "Loading table Person_Address: 18798/19614 rows ✓\n",
      "Loading table HumanResources_Employee: 100% ✓\n",
      "Loading table Sales_Store: 100% ✓\n",
      "Loading table Sales_Customer: 100% ✓\n",
      "Loading table Production_ProductCategory: 100% ✓\n",
      "Loading table Suppliers: 100% ✓\n",
      "Loading table Production_Product: 512/591 rows ✓\n",
      "Loading table Production_BillOfMaterials: 100% ✓\n",
      "Loading table Purchasing_Vendor: 100% ✓\n",
      "Loading table Purchasing_PurchaseOrderHeader: 100% ✓\n",
      "Loading table Purchasing_PurchaseOrderDetail: 100% ✓\n",
      "Loading table Sales_SalesOrderHeader: 28489/32945 rows ✓\n",
      "Loading table Sales_SalesOrderDetail: 60398/124575 rows ✓\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "\n",
    "def format_value(value, column_name, table_name):\n",
    "    reserved_keywords = ['order', 'select', 'from', 'insert', 'update', 'delete', 'where', 'join', 'into', 'group', 'name', 'state']\n",
    "\n",
    "    if column_name.lower() in reserved_keywords:\n",
    "        column_name = f\"[{column_name}]\"\n",
    "\n",
    "    if pd.isna(value):\n",
    "        return \"NULL\"\n",
    "\n",
    "    if isinstance(value, bool):\n",
    "        return \"1\" if value else \"0\"\n",
    "\n",
    "    if column_name.lower() in ['phone', 'zip_code']:\n",
    "        return f\"'{str(value)}'\"\n",
    "    \n",
    "    if column_name.lower() == \"customerid\" and table_name.lower() != \"Sales_Customer\":\n",
    "        return f\"'{str(value)}'\"\n",
    "    \n",
    "    elif isinstance(value, str):\n",
    "        if value == \"\":\n",
    "            return \"NULL\"\n",
    "        return f\"'{value.replace(\"'\", \"''\")}'\"\n",
    "    \n",
    "    elif isinstance(value, pd.Timestamp):\n",
    "        return f\"'{value.strftime('%Y-%m-%d')}'\"\n",
    "    \n",
    "    elif isinstance(value, bytes):\n",
    "        hex_value = value.hex()\n",
    "        return f\"0x{hex_value}\"\n",
    "    \n",
    "    elif isinstance(value, (int, float)):\n",
    "        return str(value)\n",
    "    \n",
    "    return f\"'{str(value)}'\"\n",
    "\n",
    "def format_table_name(table_name):\n",
    "    reserved_keywords = ['order', 'select', 'from', 'insert', 'update', 'delete', 'where', 'join', 'into', 'state']\n",
    "\n",
    "    if table_name.lower() in reserved_keywords:\n",
    "        return f\"[{table_name}]\"\n",
    "    \n",
    "    return table_name \n",
    "\n",
    "export_cursor = export_conn.cursor()\n",
    "\n",
    "for table_name, df in sdm.items():\n",
    "\n",
    "    error_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    try:\n",
    "        print(f\"Loading table {table_name}:\", end=\" \")\n",
    "\n",
    "        formatted_table_name = format_table_name(table_name)\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            total_count += 1\n",
    "\n",
    "            columns = df.columns.tolist()\n",
    "\n",
    "            if 'rowguid' in columns:\n",
    "                columns.remove('rowguid')\n",
    "\n",
    "            formatted_columns = [\n",
    "                f\"[{col}]\" if col.lower() in ['order', 'select', 'from', 'insert', 'update', 'delete', 'where', 'join', 'into', 'group', 'name'] else col\n",
    "                for col in columns\n",
    "            ]\n",
    "\n",
    "            values = []\n",
    "            for col in columns:\n",
    "                value = row[col]\n",
    "                values.append(format_value(value, col, table_name))\n",
    "\n",
    "            column_names = \", \".join(formatted_columns)\n",
    "            value_string = \", \".join(values)\n",
    "\n",
    "            query = f\"INSERT INTO {formatted_table_name} ({column_names}) VALUES ({value_string})\"\n",
    "            try:\n",
    "                export_cursor.execute(query)\n",
    "            except pyodbc.Error as e:\n",
    "                error_count += 1\n",
    "                continue\n",
    "    \n",
    "        export_conn.commit()\n",
    "        \n",
    "\n",
    "        passed_count = total_count - error_count\n",
    "\n",
    "        if error_count == 0:\n",
    "            print(f\"100% ✓\")\n",
    "        else:\n",
    "            print(f\"{passed_count}/{total_count} rows ✓\")\n",
    "\n",
    "    except pyodbc.Error as e:\n",
    "        print(\"✗ ERROR\")\n",
    "        print(f\"{query}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "export_cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
