{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP PROJECT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importeer pandas voor DataFrames en pyodbc voor database-connecties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "\n",
    "aenc_conn = sqlite3.connect(\"../../../Data/Raw/Sqlite/aenc.sqlite\")\n",
    "adventureworks_conn = sqlite3.connect(\"../../../Data/Raw/Sqlite/AdventureWorks.sqlite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database Connectie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_SDM = {\"servername\": r\"143.177.235.181\", \"database\": \"DEDSp1\", \"username\": \"sa\", \"password\": \"Str0ngP@ssword\"}\n",
    "DB_NorthWind = {\"servername\": r\"143.177.235.181\", \"database\": \"NorthWind\", \"username\": \"sa\", \"password\": \"Str0ngP@ssword\"}\n",
    "export_conn = pyodbc.connect(\n",
    "    f\"DRIVER={{ODBC Driver 18 for SQL Server}};\"\n",
    "    f\"SERVER={DB_SDM['servername']};\"\n",
    "    f\"DATABASE={DB_SDM['database']};\"\n",
    "    f\"UID={DB_SDM['username']};\"\n",
    "    f\"PWD={DB_SDM['password']};\"\n",
    "    f\"Encrypt=yes;TrustServerCertificate=yes;\"\n",
    ")\n",
    "\n",
    "NorthWind_conn = pyodbc.connect(\n",
    "    f\"DRIVER={{ODBC Driver 18 for SQL Server}};\"\n",
    "    f\"SERVER={DB_NorthWind['servername']};\"\n",
    "    f\"DATABASE={DB_NorthWind['database']};\"\n",
    "    f\"UID={DB_NorthWind['username']};\"\n",
    "    f\"PWD={DB_NorthWind['password']};\"\n",
    "    f\"Encrypt=yes;TrustServerCertificate=yes;\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames maken voor tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading sysdiagrams: Could not decode to UTF-8 column 'definition' with text '��\u0011���\u001a�'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saadz\\AppData\\Local\\Temp\\ipykernel_15716\\1853655394.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  table_names = pd.read_sql(query, connection)\n",
      "C:\\Users\\saadz\\AppData\\Local\\Temp\\ipykernel_15716\\1853655394.py:17: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dictionary[table] = pd.read_sql(f\"SELECT * FROM {table}\", connection)\n",
      "C:\\Users\\saadz\\AppData\\Local\\Temp\\ipykernel_15716\\1853655394.py:17: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dictionary[table] = pd.read_sql(f\"SELECT * FROM {table}\", connection)\n",
      "C:\\Users\\saadz\\AppData\\Local\\Temp\\ipykernel_15716\\1853655394.py:17: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dictionary[table] = pd.read_sql(f\"SELECT * FROM {table}\", connection)\n"
     ]
    }
   ],
   "source": [
    "def create_dataframes_sql(connection, db_type):\n",
    "    dictionary : dict = {}\n",
    "    query : str = \"\"\n",
    "    key : str = \"\"\n",
    "\n",
    "    if db_type == \"sqlite\":\n",
    "        query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "        key = \"name\"\n",
    "    elif db_type == \"ssms\":\n",
    "        query = \"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE = 'BASE TABLE';\"\n",
    "        key = \"TABLE_NAME\"\n",
    "\n",
    "    table_names = pd.read_sql(query, connection)\n",
    "\n",
    "    for table in table_names[key].tolist():\n",
    "        try:\n",
    "            dictionary[table] = pd.read_sql(f\"SELECT * FROM {table}\", connection)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {table}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "aenc = create_dataframes_sql(aenc_conn, \"sqlite\")\n",
    "adventureworks = create_dataframes_sql(adventureworks_conn, \"sqlite\")\n",
    "northwind = create_dataframes_sql(NorthWind_conn, \"ssms\")\n",
    "\n",
    "#Errors en warnings zijn niet erg hier als het totaal 1 error en 4 UserWarnings zijn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries met DataFrames mergen naar één Dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "sdm = aenc | adventureworks | northwind #Alle drie mergen in één Dictionary met alle DataFrames\n",
    "\n",
    "sdm['Department'] = sdm['Department'].rename(columns={\"dept_id\": \"DepartmentID\", \"dept_name\": \"DepartmentName\"})\n",
    "sdm['HumanResources_Department'] = sdm[\"HumanResources_Department\"].rename(columns={\"Name\": \"DepartmentName\"})\n",
    "sdm['Department'] = pd.concat([sdm[\"Department\"], sdm[\"HumanResources_Department\"]], ignore_index=True)\n",
    "del sdm['HumanResources_Department']\n",
    "\n",
    "sdm['Employee'] = sdm['Employee'].rename(columns={'emp_id': 'EmployeeID', \n",
    "                                                  'emp_fname': 'FirstName', \n",
    "                                                  'emp_lname': 'LastName', \n",
    "                                                  'city': 'City', \n",
    "                                                  'state': 'Region', \n",
    "                                                  'zip_code': 'PostalCode', \n",
    "                                                  'phone': 'HomePhone', \n",
    "                                                  'start_date': 'HireDate', \n",
    "                                                  'birth_date': 'BirthDate'})\n",
    "sdm['Employees'] = pd.concat([sdm['Employees'], sdm['Employee']], ignore_index=True)\n",
    "del sdm['Employee']\n",
    "\n",
    "\n",
    "\n",
    "#Hier komt veranderen van Employee en Department zodat het overeenkomt met Source Data Model\n",
    "\n",
    "#dict_order = [] #Hierin komt dictionary order te staan.\n",
    "                 #Dit moet omdat de volgorde van welke tables worden gestuurd naar database belangrijk is.\n",
    "\n",
    "#sdm = {k: sdm[k] for k in dict_order if k in sdm} #Verandert de volgorde van sdm-Dictionary.\n",
    "\n",
    "print(len(list(sdm.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDM in SSMS vullen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_cursor = export_conn.cursor()\n",
    "\n",
    "for table_name, df in sdm.items():\n",
    "    try:\n",
    "        for index, row in df.iterrows():\n",
    "            columns = df.columns.tolist()\n",
    "\n",
    "            values = []\n",
    "            for col in columns:\n",
    "                value = row[col]\n",
    "\n",
    "                if pd.isna(value):\n",
    "                    values.append(\"NULL\")\n",
    "\n",
    "                elif isinstance(value, str):\n",
    "                    values.append(f\"'{value.replace(\"'\", \"''\")}'\")\n",
    "\n",
    "                else:\n",
    "                    values.append(str(value))\n",
    "\n",
    "            column_names = \", \".join(columns)\n",
    "            value_string = \", \".join(values)\n",
    "            query = f\"INSERT INTO {table_name} ({column_names}) VALUES ({value_string})\"\n",
    "\n",
    "            export_cursor.execute(query)\n",
    "\n",
    "        export_conn.commit()\n",
    "        print(f\"Table {table_name} complete!\")\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"Error in table: {table_name}\")\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "export_cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
